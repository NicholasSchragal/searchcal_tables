{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from astropy.table import QTable, Table\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from pathlib import Path, PurePath\n",
    "from glob import glob\n",
    "import datetime\n",
    "\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0313240312354817 mas\n"
     ]
    }
   ],
   "source": [
    "wanted_columns = [\n",
    "    \"SIMBAD\",\n",
    "    \"HD\",\n",
    "    \"HIP\",\n",
    "    \"SpType\",\n",
    "    \"RotVel\", # km/s, v sin(i)\n",
    "    \"V\",\n",
    "    \"R\",\n",
    "    \"H\",\n",
    "    \"K\",\n",
    "    \"LDD\",\n",
    "    \"e_LDD\",\n",
    "    \"e_LDD_rel\",\n",
    "    \"UD_V\",\n",
    "    \"UD_R\",\n",
    "    \"UD_H\",\n",
    "    \"UD_K\",\n",
    "    \"vis2\",\n",
    "    \"vis2Err\",\n",
    "]\n",
    "\n",
    "hard_cuts = {\n",
    "    \"R\": [-2, 5.5],\n",
    "    \"H\": [-2, 5.5],\n",
    "    \"LDD\": [0, 0.7],\n",
    "    \"Sep\": [0 * u.deg, 10 * u.deg],\n",
    "#    \"RotVel\": [0, 100],\n",
    "}\n",
    "\n",
    "optimal_dra = 0.5 * u.hourangle\n",
    "\n",
    "max_baseline = 330 * u.m\n",
    "obs_wavelength = 1.65 * u.um\n",
    "min_scale = ((obs_wavelength / max_baseline) * u.rad).to(u.mas)\n",
    "print(min_scale)\n",
    "\n",
    "searchcal_out_table_dir = Path(\"./searchcal_output/\")\n",
    "sifted_table_dir = Path(\"./spica_tables/\")\n",
    "sifted_table_pattern = sifted_table_dir / \"stem.ecsv\"\n",
    "\n",
    "searchcal_tables = glob(str(searchcal_out_table_dir/\"*.csv\"))\n",
    "#print(searchcal_tables)\n",
    "\n",
    "wiki_wanted_columns = [ # Column name, unit, precision\n",
    "    [\"SIMBAD\", None, None],\n",
    "    [\"HD\", None, 0],\n",
    "    [\"HIP\", None, 0],\n",
    "    [\"Sep\", u.deg, 2],\n",
    "    [\"RASep\", u.hourangle, 2],\n",
    "    [\"DECSep\", u.deg, 2],\n",
    "    [\"OPTSep\", u.deg, 2],\n",
    "    [\"SpType\", None, None],\n",
    "    [\"RotVel\", None, 1], # km/s, v sin(i)\n",
    "    [\"V\", None, 2],\n",
    "    [\"R\", None, 2],\n",
    "    [\"H\", None, 2],\n",
    "    [\"K\", None, 2],\n",
    "    [\"LDD\", None, 3],\n",
    "    [\"e_LDD\", None, 3],\n",
    "    [\"e_LDD_rel\", None, 3],\n",
    "    [\"UD_V\", None, 3],\n",
    "    [\"UD_R\", None, 3],\n",
    "    [\"UD_H\", None, 3],\n",
    "    [\"UD_K\", None, 3],\n",
    "    [\"vis2\", None, 3],\n",
    "    [\"vis2Err\", None, 3],\n",
    "    [\"Scores\", None, 1],    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in searchcal_tables:\n",
    "    df = pd.read_csv(t, comment = \"#\")\n",
    "    df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "    searchcal_table = Table(df.values, names = df.columns)\n",
    "    coords = []\n",
    "    dists = []\n",
    "    ra_dists = []\n",
    "    dec_dists = []\n",
    "    optimal_point_dists = []\n",
    "    row1 = searchcal_table[0]\n",
    "    row1_coord = SkyCoord(row1[\"RAJ2000\"], row1[\"DEJ2000\"], unit = (u.hourangle, u.deg))\n",
    "    optimal_points = [\n",
    "        SkyCoord(ra=row1_coord.ra - optimal_dra, dec=row1_coord.dec),\n",
    "        SkyCoord(ra=row1_coord.ra + optimal_dra, dec=row1_coord.dec),        \n",
    "    ]\n",
    "\n",
    "    for row in searchcal_table:\n",
    "        coord = SkyCoord(row[\"RAJ2000\"], row[\"DEJ2000\"], unit = (u.hourangle, u.deg))\n",
    "        coords.append(coord)\n",
    "        dist = row1_coord.separation(coord)\n",
    "        dists.append(dist)\n",
    "        ra_dist = (coord.ra - row1_coord.ra).to(u.hourangle)\n",
    "        ra_dists.append(ra_dist)\n",
    "        dec_dist = (coord.dec - row1_coord.dec).to(u.deg)\n",
    "        dec_dists.append(dec_dist)\n",
    "\n",
    "        if np.isclose(dist, 0):\n",
    "            optimal_point_dists.append(np.nan * u.deg)\n",
    "            continue\n",
    "        \n",
    "        optimal_seps = []\n",
    "        for p in optimal_points:\n",
    "            optimal_seps.append(p.separation(coord).to(u.deg).value)\n",
    "        optimal_point_dists.append(np.amin(optimal_seps) * u.deg)\n",
    "\n",
    "    eval_table = searchcal_table[wanted_columns]\n",
    "\n",
    "    eval_table.add_columns((coords, dists, ra_dists, dec_dists, optimal_point_dists), indexes = (3, 3, 3, 3, 3), names = (\"RADEC\", \"Sep\", \"RASep\", \"DECSep\", \"OPTSep\"))\n",
    "\n",
    "    def CutTable(table, cuts = hard_cuts):\n",
    "        for col, lims in cuts.items():\n",
    "            table = table[np.logical_and(table[col] >= lims[0], table[col] <= lims[1])]\n",
    "        return table\n",
    "\n",
    "    cut_table = CutTable(eval_table)\n",
    "\n",
    "    new_HDs = []\n",
    "    for hd in cut_table['HD']:\n",
    "        new_HDs.append(\"{:0.0f}\".format(hd).strip(\".\"))\n",
    "    cut_table['HD'] = new_HDs\n",
    "\n",
    "    def CalibratorScore(row):\n",
    "        if np.isclose(row[\"Sep\"], 0):\n",
    "            return np.inf\n",
    "\n",
    "        # Separation from optimal calibrator placement\n",
    "        ra_score = np.abs(optimal_dra.value - np.abs(row['RASep']))\n",
    "        ra_scale = 0.1\n",
    "        \n",
    "        optsep_score = 10 - row['OPTSep']\n",
    "        optsep_scale = 0.1\n",
    "\n",
    "        # Rotational Velocity Score\n",
    "        rotvel_score = float(row['RotVel'] < 200)\n",
    "        rotvel_scale = 1.0\n",
    "\n",
    "        # UDD Score\n",
    "        udd_score = float(row['UD_H'] < min_scale.to(u.mas).value)\n",
    "        udd_scale = 0.0\n",
    "\n",
    "        # LDD Score\n",
    "        ldd_score = 0.7 - row['LDD']\n",
    "        ldd_scale = 10.0\n",
    "\n",
    "        # Rmag Score\n",
    "        rmag_score = 5.5 - row['R']\n",
    "        rmag_scale = 5.0\n",
    "\n",
    "        # Rotational velocity score\n",
    "        rotvel_score = int(row['RotVel'] < 100)\n",
    "        rotvel_scale = 100.0\n",
    "\n",
    "        # Generate final score\n",
    "        score = 0\n",
    "        score += ra_score * ra_scale\n",
    "        score += optsep_score * optsep_scale\n",
    "        score += rotvel_score * rotvel_scale\n",
    "        score += udd_score * udd_scale\n",
    "        score += ldd_score * ldd_scale\n",
    "        score += rmag_score * rmag_scale\n",
    "\n",
    "        return score\n",
    "\n",
    "    scores = []\n",
    "    score_breakdowns = []\n",
    "    for idx, row in enumerate(cut_table):        \n",
    "        score = CalibratorScore(row)\n",
    "        scores.append(score)\n",
    "\n",
    "    cut_table.add_column(scores, index = -1, name = \"Scores\")\n",
    "\n",
    "    cut_table.sort(\"Scores\", reverse = True)\n",
    "\n",
    "    outfname = Path(t).stem\n",
    "\n",
    "    outpath = PurePath(sifted_table_pattern).with_stem(outfname)\n",
    "\n",
    "    if save:\n",
    "        cut_table.write(str(outpath), overwrite = True)\n",
    "\n",
    "    mkdown_out = cut_table.to_pandas().to_markdown(index = False)\n",
    "\n",
    "    mkdown_outpath = outpath.with_suffix(\".md\")\n",
    "\n",
    "    if save:\n",
    "        with open(mkdown_outpath, 'w') as f:\n",
    "            f.write(mkdown_out)\n",
    "\n",
    "    # The below was generated using GPT-4o and modified\n",
    "\n",
    "    def is_float_like(value):\n",
    "        # Check if the value is a float or a numpy float type\n",
    "        if isinstance(value, float):\n",
    "            return True\n",
    "        elif isinstance(value, np.float32) or isinstance(value, np.float64):\n",
    "            return True\n",
    "        elif isinstance(value, np.generic):\n",
    "            # Check if it's a numpy scalar and not an integer\n",
    "            return not isinstance(value, (np.int32, np.int64, np.int8, np.int16, np.intc))\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    # Function to convert DataFrame to MediaWiki table format\n",
    "    def df_to_mediawiki(df):\n",
    "        # Start with the table header\n",
    "        mediawiki_table = \"== Interferometric Calibrator Table - CHARA/SPICA ==\\n\"\n",
    "        mediawiki_table += \"{| class=\\\"wikitable\\\"\\n\"\n",
    "        \n",
    "        # Add the header row\n",
    "        unit_string = \"\\nUnits -\"\n",
    "        mediawiki_table += \"|+\\n\"\n",
    "        for c in wiki_wanted_columns:\n",
    "            mediawiki_table += \"!{}\\n\".format(c[0])\n",
    "            if c[1] is not None:\n",
    "                unit_string += \" {}: {}\".format(c[0], str(c[1]).strip())\n",
    "\n",
    "\n",
    "        # Add each row of the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            mediawiki_table += \"|-\\n\"\n",
    "            wiki_wc_last = len(wiki_wanted_columns) - 1\n",
    "            for idx, c in enumerate(wiki_wanted_columns):\n",
    "                name = c[0]\n",
    "                prec = c[2]\n",
    "\n",
    "                value = row[name]\n",
    "                \n",
    "                if prec is None:\n",
    "                    valstr = str(value)\n",
    "                elif prec == 0:\n",
    "                    valstr = str(round(float(value), prec)).split(\".\")[0]\n",
    "                else:\n",
    "                    valstr = str(round(float(value), prec))\n",
    "                \n",
    "                \n",
    "\n",
    "                if idx != wiki_wc_last:\n",
    "                    mediawiki_table += \"| {} |\".format(valstr)\n",
    "                else:\n",
    "                    mediawiki_table += \"| {}\\n\".format(valstr)\n",
    "\n",
    "#            rowlen = len(row)\n",
    "#            for idx, value in enumerate(row):\n",
    "#                if idx == rowlen-1:\n",
    "#                    if is_float_like(value):\n",
    "#                        mediawiki_table += \"| \" + str(np.round(value, 3)) + \"\\n\"\n",
    "#                    else:\n",
    "#                        mediawiki_table += \"| \" + str(value) + \"\\n\"\n",
    "#                else:\n",
    "#                    if is_float_like(value):\n",
    "#                        mediawiki_table += \"| \" + str(np.round(value, 3)) + \" |\"\n",
    "#                    else:\n",
    "#                        mediawiki_table += \"| \" + str(value) + \" |\"\n",
    "        \n",
    "        # End the table\n",
    "        mediawiki_table += \"|}\"\n",
    "\n",
    "        generator_link = \"https://drive.google.com/file/d/16YFkWxVqMv6mvf3FU8qOdNuLHu1IMyWc/view?usp=sharing\"\n",
    "        generator_time = datetime.datetime.now(datetime.timezone.utc).strftime(\"%Y-%m-%d\")\n",
    "        mediawiki_table += \"\\n{}\".format(unit_string)\n",
    "        mediawiki_table += \"\\n\\nTable generated by Nick Schragal on {} using [https://github.com/NicholasSchragal/searchcal_tables methodology described here].\".format(generator_time)\n",
    "        \n",
    "        return mediawiki_table\n",
    "\n",
    "    # Convert the DataFrame to MediaWiki format\n",
    "    mediawiki_output = df_to_mediawiki(cut_table.to_pandas())\n",
    "    # Write the output to a text file\n",
    "    if not save:print(mediawiki_output)\n",
    "    if save:\n",
    "        with open(outpath.with_suffix(\".txt\"), 'w') as f:\n",
    "            f.write(mediawiki_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exosims-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
